---
{"dg-publish":true,"permalink":"/projects/ocr-data-centric/","created":"2024-11-25T11:09:06.427+09:00","updated":"2025-02-16T02:25:00.917+09:00"}
---

## 프로젝트 개요
- 2024.10.28 ~ 2024.11.7
- 영수증 글자 인식을 위한 OCR 대회
- Data-Centric AI 관점 대회
- Naver Connect & Upstage 주관 대회

---
## 대회 소개
![Pasted_image_20250215211658.png](/img/user/Pasted_image_20250215211658.png)
카메라로 영수증을 인식할 경우 자동으로 영수증 내용이 입력되는 어플리케이션이 있습니다. 이처럼 **OCR** (Optical Character Recognition) 기술은 사람이 직접 쓰거나 이미지 속에 있는 문자를 얻은 다음 이를 컴퓨터가 인식할 수 있도록 하는 기술로, 컴퓨터 비전 분야에서 현재 널리 쓰이는 대표적인 기술 중 하나입니다.

본 대회는 **Data-Centric AI**의 관점에서 모델 활용을 경쟁하는 대회입니다. 이에 따라 제공되는 베이스라인 코드 중 모델 관련 부분을 변경하는 것이 금지되어 있습니다. 보통의 대회에서는 AI 모델의 구조나 기술에 집중하지만 모델만큼이나 중요한 **데이터의 관점**에서 (데이터 정제, 제작, 성능 평가, 후처리 등) 다양한 방식으로 모델의 성능을 향상시키는 대회입니다. 

---
## 개발 환경
- Language : Python
- Environment
	- CPU : Intel(R) Xeon(R) Gold 5120
	- GPU : Tesla V100-SXM2 32GB x 1
- Framework : PyTorch
- Collaborative Tool : GitHub, Tensorboard, Notion

---
## Leaderboard
![Pasted image 20250216013100.png](/img/user/Pasted%20image%2020250216013100.png)
	이번 대회에서는 10등이라는 높지도 낮지도 않은 결과를 얻게 되었습니다. 하지만, 그 전 대회의 내용들보다 더욱 많이 배울 수 있는 기회가 되었습니다. 데이터 중심의 AI라는 대회의 특성 상 전처리, 데이터 제작, 외부 데이터 사용 등 다양한 가설을 설정하고 시도를 해볼 수 있었습니다. 한 가지 아쉬운 점은 대회 규정상 모델 코드 변경 관리에 대한 문제로 데이터 전처리 부분이 금지된 점이었습니다. 해당 대회에서 저는 전처리를 위주로 진행했지만 테스트셋 데이터의 전처리 작업은 금지되었기 때문에 최종 결과에 적용하지는 못했습니다. 

---
## 타임라인
![Pasted_image_20241125114625.png](/img/user/Pasted_image_20241125114625.png)

---
## 프로젝트 수행 내용

다국어 영수증 OCR 프로젝트에서 F1-Score를 향상시키기 위해서는 정확한 Bounding Box를 Detection하는 것이 중요합니다. 그러기 위해서 저는 다음과 같은 시도를 하였습니다.
- 데이터 수집
- 데이터 클렌징 및 라벨링
- 데이터 해상도 변경
- 데이터 전처리(이진화 및 수평 정렬)

---
## 문제 해결
### 데이터 수집
- 문제 상황
	- 주어진 데이터셋은 중국어, 일본어, 베트남어, 태국어, 총 4가지 언어가 100장씩으로 이루어진 다국어 영수증 데이터셋이였습니다. 하지만, 400장의 데이터셋은 모델이 충분히 학습을 하기에는 부족한 데이터양이라고 판단하였습니다.
- 가설
	- 다양한 언어에서의 모델의 일반화 성능을 올리기 위해서 4가지 언어 외의 다른 언어의 데이터셋을 통해 학습을 진행하는 것도 도움이 될 것이라고 생각했습니다.
- 실험 설계 
	- 따라서 비교적 데이터가 많이 존재하는 영어 영수증 데이터셋인 CORD 1,000장, SROIE 1,000장, WILD 1,000장을 확보한 뒤, 결과를 확인해보았습니다.
	- 출처
		- [CORD](https://huggingface.co/datasets/naver-clova-ix/cord-v2)
		- [SORIE](https://paperswithcode.com/dataset/sroie)
		- [WILD](https://paperswithcode.com/dataset/wildreceipt)
- 결과 및 분석
	- 수집한 데이터셋을 활용하여 학습을 진행한 결과, **CORD 200장과 SORIE 1,000장**을 추가하여 학습을 진행하였을 때 **0.7890**으로 성능이 가장 높게 나왔습니다.
	- 영어 데이터셋을 학습에 추가하였을 때, 성공적으로 성능이 향상된 것을 볼 수 있었습니다.
	- 단, WILD 데이터셋은 흐릿한 이미지나 노이즈가 너무 심한 이미지로 이루어져 있어 추가하였을 때, 오히려 성능이 떨어지는 것을 확인하여 학습 데이터셋에서 제외하였습니다. 
	- 또한, CORD 데이터셋의 경우 제공된 기본 데이터셋과는 달리 영수증 구분선(점선, 실선 등)에 대해 Bounding Box Ground Truth가 누락되어 있어 1,000장을 추가하였을 때 200장에 비해 성능이 하락하였습니다.

| 학습 데이터셋                                 | F1-Score(Test) |
| --------------------------------------- | -------------- |
| BaseLine                                | 0.6886         |
| BaseLine + CORD 200장                    | 0.7780         |
| BaseLine + CORD 1,000장                  | 0.7738         |
| **BaseLine + CORD 200장 + SORIE 1,000장** | **0.7890**     |
| BaseLine + CORD 200장 + WILD 1,000장      | 0.7593         |

### 데이터 클렌징 및 라벨링
- 문제 상황
	- 위 CORD 데이터셋을 정성적으로 확인한 결과, 영수증이 접혀있거나, 기울어진 경우에 Bounding box가 부정확하게 형성되어 있었고 구분선(점선, 실선 등)에 대해 Bounding Box Ground Truth가 누락되어 있다는 문제를 확인하였습니다.
- 가설
	- 따라서 이를 해결하기 위해 데이터 클렌징과 재라벨링을 적용한 뒤 학습을 진행하면 성능 향상이 될 것이라고 생각하였습니다.
- 실험 설계 
	- CVAT 어노테이션 툴을 활용하여 팀원들과 함께 CORD 데이터셋을 직접 수정한 뒤 학습을 진행하였습니다.
	- 부정확한 Ground Truth Bounding Box 예제
	  ![Pasted image 20250216005650.png](/img/user/Pasted%20image%2020250216005650.png)
	- 구분선 재라벨링 전과 후
	  ![Pasted image 20250216005656.png](/img/user/Pasted%20image%2020250216005656.png)
- 결과 및 분석
	- 기본 데이터셋에 수정된 CORD 데이터셋 200장을 추가하여 학습을 진행하였지만, 기존의 베스트 성능보다는 떨어진 결과를 얻었습니다. 
	- 또한, 기존 베스트 성능 모델 가중치에 수정된 CORD 데이터셋을 활용하여 FineTuning도 진행해보았지만 유의미한 성능 향상은 얻지 못했습니다.
	- 위와 같은 결과를 얻은 원인으로, 높은 성능을 위해서는 질 좋은, 충분한 데이터가 필요하지만 수정된 CORD 데이터셋은 경진대회라는 특성 상 부족한 시간으로 인해 충분한 데이터양을 충족하지 못했기 때문이라고 생각합니다.

### 이미지 해상도 변경
- 문제 상황
	- 초기 BaseLine 모델의 경우 입력 이미지 크기를 1024로 리사이즈하여 학습하고 있어 원본 이미지의 정보가 손실된다는 문제가 있었습니다.
- 가설
	- 따라서 원본 이미지의 정보 손실이 최소화 하면서 모델에서의 최적의 입력 사이즈를 찾으면 성능 향상이 이뤄질 것이라고 생각하였습니다. 
- 실험 설계
	- 입력 이미지의 크기를 다양하게 조절한 뒤 학습을 진행하여 결과를 비교하였습니다.
- 결과 및 분석
	- 그 결과, 1536의 이미지 크기에서 가장 높은 성능 향상이 이루어졌습니다.
	  ![Pasted image 20250216011211.png](/img/user/Pasted%20image%2020250216011211.png)

### 최종 데이터 수집 및 추가
- 문제 상황
	- 프로젝트 마무리 단계에서 부족한 부분을 찾기 위해 예측 결과를 시각화하여 정성적으로 확인하였습니다. 
	- 그 결과, 베트남 및 태국어와 같은 특정 언어 모양을 정확히 인지하지 못한다는 문제를 확인하였습니다.
- 가설
	- 따라서 베트남, 태국어의 문장 이미지 데이터를 추가하여 취약 언어에서의 특징 추출 성능을 올리면 최종 Test 성능의 향상으로 이루어질 것이라고 생각하였습니다.
- 실험 설계
	- Kaggle의 베트남, 태국어 문장 이미지 데이터 10,000장을 학습시킨 뒤 Test 성능을 비교하였습니다.
	- 베트남, 태국어 문장 이미지 데이터 예시(위 베트남, 아래 태국어)
	  ![Pasted image 20250216012810.png](/img/user/Pasted%20image%2020250216012810.png)
	  ![Pasted image 20250216012816.png](/img/user/Pasted%20image%2020250216012816.png)
- 결과 및 분석
	- 성능 비교 결과, 유의미한 성능 향상을 보여 해당 데이터 셋을 최종적으로 학습에 활용하였습니다.

| 학습 데이터셋  | F1-Score(Test) |
| -------- | -------------- |
| 문장 데이터 X | 0.82           |
| 문장 데이터 O | 0.88           |
### 데이터 전처리(이진화)
- 문제 상황
	- Train 데이터와 Test 데이터의 **그림자, 조명, 구겨짐** 등의 차이로 인해 Test 데이터셋에서 정확한 글자 영역 추출이 안되는 문제를 확인하였습니다.
- 가설
	- 영수증 이미지는 대체로 흰 배경 위에 검은 글씨로 정보가 표시되어 있어 명암 대비 비교적 뚜렷합니다.
	- 따라서 이미지 이진화 전처리를 통해 Train 데이터와 Test 데이터의 분포 차이를 줄이면 성능이 향상될 것이라고 생각하였습니다.
- 실험 설계
	- 노이즈 제거 및 Adaptive Thresholding을 활용해 데이터 전처리를 진행하고 그 결과를 비교 분석하였습니다.
	- 원본 이미지(왼)와 이진화 전처리(오)를 적용한 이미지
	  ![Pasted image 20250216020211.png](/img/user/Pasted%20image%2020250216020211.png)
- 결과 분석
	- 이진화 전처리를 적용한 경우 Validation 데이터셋에서 F1-Score 기준 0.69에서 0.75로 8.7%의 성능 향상을 확인하였습니다.
	- 하지만, 대회 규정상 테스트 데이터셋에 전처리를 적용하는 것이 금지되어 있어 이후 본 대회에 적용은 하지 못하였습니다.

### 데이터 전처리(수평정렬)
- 문제 상황
	- Train 데이터와 Test 데이터의 **기울어진** 각도 차이로 인해 Test 데이터셋에서 정확한 글자 영역 추출이 안되는 문제를 확인하였습니다.
- 가설
	- 영수증 이미지는 주로 직사각형 형태의 외곽 정보를 지니고 있습니다.
	- 이러한 구조적 특성을 활용해 기울어진 영수증 이미지의 각도를 바로 잡아 Train 데이터와 Test 데이터의 분포 차이를 줄이면 성능 향상으로 이루어 질 것이라고 생각했습니다.
- 실험 설계
	- Gaussian 필터를 활용한 Noise 제거 및 Canny edge detection을 활용하여 영수증의 외곽선 정보를 검출하였습니다.
	- 기울어진 각도를 추정하기 위해 각도 별 Histogram 분포를 활용하였습니다. 
	- 이후 Skew Correction 과정에서 이미지의 세로 및 가로 방향의 히스토그램 값 차이가 최대화되도록 최적의 회전 각도를 찾아 정렬을 진행하였습니다.
	- Edge Detection 과정. 원본 이미지(왼), 노이즈 제거 이미지(중앙), Edge 이미지(오)
	  ![Pasted image 20250216021348.png](/img/user/Pasted%20image%2020250216021348.png)
	- Skew Correction 과정. Edge 이미지(왼), Edge의 최적 각도(중앙), 수평 정렬된 이미지(오)
	  ![Pasted image 20250216021447.png](/img/user/Pasted%20image%2020250216021447.png)
- 결과 및 분석
	- 본 연구에서 적용한 Skew Correction 기법은 다양한 각도에서 촬영된 영수증 이미지에서도 높은 정렬 정확도를 보였으며, OCR성능 향상에 대한 가능성을 확인할 수 있었습니다.
	- 하지만, 대회 규정상 테스트 데이터셋에 전처리를 적용하는 것은 금지되어 있기 때문에 추후 적용은 하지 않았습니다.

---
## 결론
최종적으로 모델의 구조와 기법을 바꾸지 않고, 오직 데이터 수집, 데이터 증강, 하이퍼파라미터 튜닝 들을 통해 다국어 영수증 OCR Task F1-Score 성능을 올릴 수 있었습니다.

외부 데이터셋을 수집하고 클렌징 및 전처리를 수행하였고 예측 결과를 시각화하여 문제를 파악하였습니다.

특히 대회 규정상 사용하진 못했지만 OCR Task에서 적절한 데이터 전처리(데이터 이진화 및 수평 정렬 기법)를 통해 유의미하게 성능을 향상시킬 수 있는 기법들을 발견했습니다. 

마지막으로, 언어 검출에 특화된 모델의 결과와 구분선(점선 및 실선)을 잘 검출하는 모델의 결과를 앙상블하여 최종 0.9034결과를 얻어 BaseLine 기준 21.5%의 성능 향상을 이끌어 냈습니다.

- 최종 결과

| Data-Centric AI      | F1-Score(Test) |
| -------------------- | -------------- |
| BaseLine             | 0.6886         |
| Ours Data-Centric AI | 0.9034         |
